# >>>>> START: /mnt/d/NEW_GUI/emotion_labels.py <<<<<

	def get_emotion_labels():
	    return ["Neutral", "Happiness", "Surprise", "Sadness", "Anger", "Disgust", "Fear"]

# <<<<< END: /mnt/d/NEW_GUI/emotion_labels.py >>>>>

# >>>>> START: /mnt/d/NEW_GUI/main.py <<<<<

	import sys
	import torch
	from PyQt5.QtWidgets import QApplication, QFileDialog, QMessageBox
	from PyQt5.QtCore import QTimer
	from ui_setup import UIComponents, LoginDialog
	from video_processing import VideoProcessing
	from model_handling import ModelHandling

	class MicroExpressionApp(UIComponents):
	    def __init__(self):
	        super().__init__()
	        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
	        self.model_handler = None
	        self.video_processor = VideoProcessing(self.device)
	        self.timer = QTimer()
	        self.timer.timeout.connect(self.update_frame)
	        self.login_dialog = LoginDialog()
	        self.login_dialog.exec_()
	        self.start_stop_button.clicked.connect(self.toggle_video)
	        self.load_model_button.clicked.connect(self.load_model)

	    def load_model(self):
	        model_path, _ = QFileDialog.getOpenFileName(self, 'Load Model', '', 'Model Files (*.pt *.pth)')
	        if model_path:
	            self.model_handler = ModelHandling(model_path, self.device)
	            QMessageBox.information(self, 'Success', 'Model Loaded Successfully!')

	    def toggle_video(self):
	        if self.timer.isActive():
	            self.timer.stop()
	            self.start_stop_button.setText('Start')
	        else:
	            self.capture = cv2.VideoCapture(0)
	            self.timer.start(30)
	            self.start_stop_button.setText('Stop')

	    def update_frame(self):
	        ret, frame = self.capture.read()
	        if ret:
	            self.video_processor.process_frame(frame, self.model_handler.model, self.video_frame, self.trend_ax, self.pie_ax,
	                                               self.bar_ax, self.trend_canvas, self.pie_canvas, self.bar_canvas)

	if __name__ == '__main__':
	    app = QApplication(sys.argv)
	    window = MicroExpressionApp()
	    window.show()
	    sys.exit(app.exec_())

# <<<<< END: /mnt/d/NEW_GUI/main.py >>>>>

<!-- >>>>> START: /mnt/d/NEW_GUI/micro_expression_app.ui <<<<< -->

	<?xml version="1.0" encoding="UTF-8"?>
	<ui version="4.0">
	 <class>MicroExpressionApp</class>
	 <widget class="QWidget" name="MicroExpressionApp">
	  <property name="geometry">
	   <rect>
	    <x>0</x>
	    <y>0</y>
	    <width>1400</width>
	    <height>700</height>
	   </rect>
	  </property>
	  <property name="windowTitle">
	   <string>Micro-Expression Detection</string>
	  </property>
	  <layout class="QHBoxLayout" name="horizontalLayout">
	   <item>
	    <layout class="QVBoxLayout" name="verticalLayout">
	     <!-- Video Frame -->
	     <item>
	      <widget class="QLabel" name="video_frame">
	       <property name="sizePolicy">
	        <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
	         <horstretch>1</horstretch>
	         <verstretch>1</verstretch>
	        </sizepolicy>
	       </property>
	       <property name="minimumSize">
	        <size>
	         <width>640</width>
	         <height>480</height>
	        </size>
	       </property>
	      </widget>
	     </item>
	     <!-- Buttons Layout -->
	     <item>
	      <layout class="QHBoxLayout" name="horizontalLayout_2">
	       <item>
	        <widget class="QPushButton" name="start_stop_button">
	         <property name="text">
	          <string>Start Webcam</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QPushButton" name="load_model_button">
	         <property name="text">
	          <string>Load Model</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QPushButton" name="load_video_button">
	         <property name="text">
	          <string>Load Video</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QPushButton" name="play_pause_button">
	         <property name="text">
	          <string>Play</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QPushButton" name="stop_button">
	         <property name="text">
	          <string>Stop</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QPushButton" name="exit_button">
	         <property name="text">
	          <string>Exit</string>
	         </property>
	        </widget>
	       </item>
	      </layout>
	     </item>
	     <!-- Labels -->
	     <item>
	      <widget class="QLabel" name="model_name_label">
	       <property name="text">
	        <string>Loaded Model:</string>
	       </property>
	      </widget>
	     </item>
	     <item>
	      <widget class="QLabel" name="loaded_model_label">
	       <property name="text">
	        <string>-</string>
	       </property>
	      </widget>
	     </item>
	     <!-- Slider -->
	     <item>
	      <widget class="QSlider" name="video_slider">
	       <property name="orientation">
	        <enum>Qt::Horizontal</enum>
	       </property>
	       <property name="tickPosition">
	        <enum>QSlider::TicksBelow</enum>
	       </property>
	      </widget>
	     </item>
	     <!-- Frame Rate Label -->
	     <item>
	      <widget class="QLabel" name="frame_rate_label">
	       <property name="text">
	        <string>Frame Index:</string>
	       </property>
	      </widget>
	     </item>
	     <item>
	      <widget class="QLabel" name="frame_rate_value_label">
	       <property name="text">
	        <string>0</string>
	       </property>
	      </widget>
	     </item>
	     <!-- Configuration Layout -->
	     <item>
	      <layout class="QVBoxLayout" name="config_layout">
	       <item>
	        <widget class="QLabel" name="num_layers_label">
	         <property name="text">
	          <string>Num Layers:</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QSpinBox" name="num_layers_spinbox"/>
	       </item>
	       <item>
	        <widget class="QLabel" name="use_attention_label">
	         <property name="text">
	          <string>Use Attention:</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QCheckBox" name="use_attention_checkbox"/>
	       </item>
	       <item>
	        <widget class="QLabel" name="num_classes_label">
	         <property name="text">
	          <string>Num Classes:</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <widget class="QSpinBox" name="num_classes_spinbox"/>
	       </item>
	       <item>
	        <widget class="QLabel" name="dropout_label">
	         <property name="text">
	          <string>Dropout:</string>
	         </property>
	        </widget>
	       </item>
	       <item>
	        <layout class="QHBoxLayout">
	         <item>
	          <widget class="QSlider" name="dropout_slider">
	           <property name="orientation">
	            <enum>Qt::Horizontal</enum>
	           </property>
	           <property name="tickPosition">
	            <enum>QSlider::TicksBelow</enum>
	           </property>
	          </widget>
	         </item>
	         <item>
	          <widget class="QLabel" name="dropout_value_label">
	           <property name="text">
	            <string>0.0</string>
	           </property>
	          </widget>
	         </item>
	        </layout>
	       </item>
	      </layout>
	     </item>
	    </layout>
	   </item>
	   <!-- Graph Layout -->
	   <item>
	    <layout class="QVBoxLayout" name="graph_layout" margin="0" spacing="0">
	     <item>
	      <widget class="QWidget" name="trend_canvas">
	       <property name="sizePolicy">
	        <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
	         <horstretch>0</horstretch>
	         <verstretch>0</verstretch>
	        </sizepolicy>
	       </property>
	      </widget>
	     </item>
	     <item>
	      <widget class="QWidget" name="pie_canvas">
	       <property name="sizePolicy">
	        <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
	         <horstretch>0</horstretch>
	         <verstretch>0</verstretch>
	        </sizepolicy>
	       </property>
	      </widget>
	     </item>
	     <item>
	      <widget class="QWidget" name="bar_canvas">
	       <property name="sizePolicy">
	        <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
	         <horstretch>0</horstretch>
	         <verstretch>0</verstretch>
	        </sizepolicy>
	       </property>
	      </widget>
	     </item>
	    </layout>
	   </item>
	  </layout>
	 </widget>
	 <resources/>
	 <connections/>
	</ui>

<!-- <<<<< END: /mnt/d/NEW_GUI/micro_expression_app.ui >>>>> -->

# >>>>> START: /mnt/d/NEW_GUI/model_handling.py <<<<<

	import torch
	import torch.nn.functional as F
	from torchvision import transforms
	from models import MicroExpressionClassificationModel, R3D_FeatureExtractor, TransformerEncoder

	class ModelHandling:
	    def __init__(self, model_path, device):
	        self.device = device
	        self.model = None
	        self.load_model(model_path)

	    def load_model(self, model_path):
	        try:
	            checkpoint = torch.load(model_path, map_location=self.device)
	            self.feature_extractor = R3D_FeatureExtractor(d_model=512, pretrained=True, dropout_prob=0.2)
	            self.transformer_encoder = TransformerEncoder(d_model=512, nhead=8, num_layers=3, dropout=0.2)
	            self.model = MicroExpressionClassificationModel(self.feature_extractor,
	                                                            self.transformer_encoder,
	                                                            num_classes=3,
	                                                            use_attention=True)
	            if 'state_dict' in checkpoint:
	                state_dict = checkpoint['state_dict']
	            else:
	                state_dict = checkpoint

	            self.model.load_state_dict(state_dict)
	            self.model.eval()
	        except Exception as e:
	            print(f"Error loading model: {e}")

	    def predict(self, frame):
	        # Preprocess the frame if necessary (e.g., resize, normalize)
	        input_tensor = transforms.ToTensor()(frame).unsqueeze(0).to(self.device)
	        with torch.no_grad():
	            output = F.softmax(self.model(input_tensor), dim=1).squeeze()
	        return output

# <<<<< END: /mnt/d/NEW_GUI/model_handling.py >>>>>

/* >>>>> START: /mnt/d/NEW_GUI/styles.qss <<<<< */

	/* styles.qss */

	/* General QWidget styling */
	QWidget {
	    background-color: #f0f0f0; /* Light gray background */
	    color: #333; /* Dark gray text color */
	    font-size: 14px; /* Default font size */
	}

	/* QPushButton styling */
	QPushButton {
	    padding: 10px 20px; /* Padding for buttons */
	    background-color: #4682B4; /* Steel blue background */
	    color: white;
	    border: none;
	    border-radius: 5px;
	}

	QPushButton:hover {
	    background-color: #2a4e78; /* Darker steel blue on hover */
	}

	QPushButton:pressed {
	    background-color: #1c364e; /* Even darker steel blue when pressed */
	}

	/* QLabel styling */
	QLabel {
	    font-size: 16px; /* Larger font for labels */
	}

	/* QSlider styling */
	QSlider::handle {
	    background: #4682B4; /* Steel blue slider handle */
	    border: 2px solid #4682B4;
	    width: 18px;
	    margin: -8px 0;
	    border-radius: 9px;
	}

	QSlider::add-page, QSlider::sub-page {
	    background: #ddd; /* Light gray slider track */
	    border-radius: 4px;
	}

	QSlider::groove {
	    border: 1px solid #999; /* Gray border around slider */
	    height: 8px; /* Thickness of slider */
	}

	QSlider::add-page {
	    background: #ddd; /* Light gray track before handle */
	}

	QSlider::sub-page {
	    background: #4682B4; /* Steel blue track after handle */
	}

	/* QSpinBox styling */
	QSpinBox {
	    padding: 5px;
	    font-size: 14px;
	    width: 60px;
	}

	/* QCheckBox styling */
	QCheckBox {
	    font-size: 14px;
	}

/* <<<<< END: /mnt/d/NEW_GUI/styles.qss >>>>> */

# >>>>> START: /mnt/d/NEW_GUI/ui_setup.py <<<<<

	from PyQt5.QtWidgets import QWidget, QLabel, QVBoxLayout, QHBoxLayout, QPushButton, QFileDialog, \
	    QSlider, QMessageBox, QSizePolicy, QLineEdit, QDialog, QFormLayout, QSpinBox, QCheckBox, QProgressDialog
	from PyQt5.QtGui import QImage, QPixmap, QIcon, QFont, QColor, QPainter, QMovie
	from PyQt5.QtCore import QTimer, Qt, QPropertyAnimation
	from PyQt5.uic import loadUi
	from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
	from matplotlib.figure import Figure

	class HoverButton(QPushButton):
	    def __init__(self, text, parent=None):
	        super().__init__(text, parent)
	        self.setMouseTracking(True)

	    def enterEvent(self, event):
	        self.animate_hover(True)

	    def leaveEvent(self, event):
	        self.animate_hover(False)

	    def animate_hover(self, hover):
	        animation = QPropertyAnimation(self, b'background-color')
	        animation.setDuration(200)
	        if hover:
	            animation.setEndValue(QColor('#45a049'))  # Darker green on hover
	        else:
	            animation.setEndValue(QColor('#4CAF50'))  # Original green
	        animation.start()

	class LoginDialog(QDialog):
	    def __init__(self):
	        super().__init__()
	        self.setWindowTitle('Login')
	        self.username_input = QLineEdit()
	        self.password_input = QLineEdit()
	        self.password_input.setEchoMode(QLineEdit.Password)
	        self.login_button = QPushButton('Login')
	        self.login_button.clicked.connect(self.check_credentials)

	        layout = QVBoxLayout()
	        layout.addWidget(QLabel('Username:'))
	        layout.addWidget(self.username_input)
	        layout.addWidget(QLabel('Password:'))
	        layout.addWidget(self.password_input)
	        layout.addWidget(self.login_button)
	        self.setLayout(layout)

	    def check_credentials(self):
	        username = self.username_input.text()
	        password = self.password_input.text()
	        if username == '' and password == '':
	            QMessageBox.information(self, 'Success', 'Login Successful!')
	            self.accept()
	        else:
	            QMessageBox.warning(self, 'Error', 'Invalid credentials')

	class UIComponents(QWidget):
	    def __init__(self):
	        super().__init__()
	        self.setup_ui()

	    def setup_ui(self):
	        loadUi('micro_expression_app.ui', self)
	        self.setWindowTitle('Micro-Expression Detection')
	        self.video_frame.setMinimumSize(900, 480)

	        font = QFont()
	        font.setPointSize(14)

	        for label in self.findChildren(QLabel):
	            label.setFont(font)
	            label.setAlignment(Qt.AlignCenter)

	        for button in [self.start_stop_button, self.load_model_button, self.load_video_button, self.exit_button,
	                       self.play_pause_button, self.stop_button]:
	            button.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Fixed)

	        self.trend_canvas = FigureCanvas(Figure(figsize=(5, 3)))
	        self.graph_layout.addWidget(self.trend_canvas)
	        self.trend_ax = self.trend_canvas.figure.subplots()
	        self.trend_ax.set_title('Emotion Trend Over Time')
	        self.trend_canvas.figure.subplots_adjust(bottom=0.20)
	        self.trend_canvas.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
	        self.trend_canvas.setMinimumSize(400, 250)

	        self.bar_canvas = FigureCanvas(Figure(figsize=(5, 3)))
	        self.graph_layout.addWidget(self.bar_canvas)
	        self.bar_ax = self.bar_canvas.figure.subplots()
	        self.bar_ax.set_title('Emotion Analysis Bar Plot')
	        self.bar_canvas.figure.subplots_adjust(bottom=0.20)
	        self.bar_canvas.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
	        self.bar_canvas.setMinimumSize(400, 300)

	        self.pie_canvas = FigureCanvas(Figure(figsize=(5, 3)))
	        self.graph_layout.addWidget(self.pie_canvas)
	        self.pie_ax = self.pie_canvas.figure.subplots()
	        self.pie_ax.set_title('Emotion Distribution')
	        self.pie_canvas.figure.subplots_adjust(bottom=0.15)
	        self.pie_canvas.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
	        self.pie_canvas.setMinimumSize(400, 300)

	        self.placeholder_label = QLabel(self)
	        self.placeholder_label.setMinimumSize(900, 480)
	        self.set_placeholder()

	        self.main_layout = QHBoxLayout(self)
	        self.main_layout.addLayout(self.verticalLayout)
	        self.main_layout.addLayout(self.graph_layout)
	        self.setLayout(self.main_layout)

	        self.num_layers_spinbox.setMinimum(1)
	        self.num_layers_spinbox.setMaximum(12)
	        self.num_layers_spinbox.setValue(3)

	        self.use_attention_checkbox.setChecked(1)
	        self.num_classes_spinbox.setMinimum(1)
	        self.num_classes_spinbox.setMaximum(100)
	        self.num_classes_spinbox.setValue(3)

	        self.dropout_slider.setOrientation(Qt.Horizontal)
	        self.dropout_slider.setRange(0, 100)
	        self.dropout_slider.setValue(20)
	        self.update_dropout_label(20)

	    def update_dropout_label(self, value):
	        self.dropout_value_label.setText(f"{value / 10:.1f}")

	    def set_placeholder(self):
	        movie = QMovie('placeholder2.gif')
	        self.placeholder_label.setMovie(movie)
	        movie.start()
	        self.placeholder_label.setAlignment(Qt.AlignCenter)

# <<<<< END: /mnt/d/NEW_GUI/ui_setup.py >>>>>

# >>>>> START: /mnt/d/NEW_GUI/video_processing.py <<<<<

	import cv2
	import numpy as np
	from torchvision import transforms
	import mediapipe as mp
	from PyQt5.QtGui import QImage, QPixmap
	import torch

	from emotion_labels import get_emotion_labels

	class VideoProcessing:
	    def __init__(self, device):
	        self.device = device
	        self.mp_face_mesh = mp.solutions.face_mesh
	        self.face_mesh = self.mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True,
	                                                    min_detection_confidence=0.8, min_tracking_confidence=0.8)

	    def process_frame(self, frame, emotion_classifier, video_frame, trend_ax, pie_ax, bar_ax, trend_canvas, pie_canvas, bar_canvas):
	        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
	        results = self.face_mesh.process(rgb_frame)

	        if results.multi_face_landmarks:
	            for face_landmarks in results.multi_face_landmarks:
	                head_outline_indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377,
	                                        152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]

	                h, w, _ = frame.shape
	                points = [(int(face_landmarks.landmark[idx].x * w), int(face_landmarks.landmark[idx].y * h)) for idx in head_outline_indices]

	                mask = np.zeros((h, w), dtype=np.uint8)
	                cv2.fillPoly(mask, [np.array(points, dtype=np.int32)], 255)
	                mask_inv = cv2.bitwise_not(mask)

	                white_background = np.full_like(frame, 255)
	                frame_white_background = cv2.bitwise_and(white_background, white_background, mask=mask_inv)
	                head_region = cv2.bitwise_and(frame, frame, mask=mask)
	                head_region_with_white_background = cv2.add(head_region, frame_white_background)

	                x, y, w, h = cv2.boundingRect(np.array(points, dtype=np.int32))
	                head_crop = head_region_with_white_background[y:y+h, x:x+w]
	                head_crop = cv2.resize(head_crop, (170, 170))

	                head_tensor = transforms.ToTensor()(head_crop).unsqueeze(0).to(self.device)

	                with torch.no_grad():
	                    probabilities = torch.nn.functional.softmax(emotion_classifier(head_tensor), dim=1).squeeze()
	                    emotion = torch.argmax(probabilities).item()

	                emotion_text = self.get_emotion_label(emotion)
	                cv2.putText(rgb_frame, emotion_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)
	                cv2.rectangle(rgb_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

	                self.update_trend_graph([emotion], trend_ax, trend_canvas)
	                self.update_pie_chart(probabilities.cpu().numpy(), pie_ax, pie_canvas)
	                self.update_bar_chart(probabilities.cpu().numpy(), bar_ax, bar_canvas)

	        rgb_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)
	        image = QImage(rgb_frame, rgb_frame.shape[1], rgb_frame.shape[0], rgb_frame.strides[0], QImage.Format_RGB888)
	        video_frame.setPixmap(QPixmap.fromImage(image))

	    @staticmethod
	    def get_emotion_label(emotion):
	        emotions = get_emotion_labels()
	        return emotions[emotion]

	    def update_trend_graph(self, emotion, trend_ax, trend_canvas):
	        trend_ax.plot(range(len(emotion)), emotion, label='Emotion')
	        trend_canvas.draw()

	    def update_pie_chart(self, probabilities, pie_ax, pie_canvas):
	        emotions = get_emotion_labels()
	        pie_ax.clear()
	        pie_ax.pie(probabilities, labels=emotions, autopct='%1.1f%%', startangle=140)
	        pie_canvas.draw()

	    def update_bar_chart(self, probabilities, bar_ax, bar_canvas):
	        emotions = get_emotion_labels()
	        bar_ax.clear()
	        bar_ax.bar(emotions, probabilities)
	        bar_canvas.draw()

# <<<<< END: /mnt/d/NEW_GUI/video_processing.py >>>>>

